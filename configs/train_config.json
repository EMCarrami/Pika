{
  "seed": 7,
  "datamodule": {
    "data_dict_path": "uniref50_gpt_data.pkl",
    "split_ratios": [0.88, 0.02, 0.1],
    "max_protein_length": 1500,
    "max_text_length": 250,
    "data_field_names": "qa",
    "sequence_placeholder": "<protein sequence placeholder> ",
    "subsample_data": 1.0,
    "train_batch_size": 8,
    "eval_batch_size": 32,
    "num_workers": 4
  },
  "model": {
    "language_model": "gpt2-medium",
    "protein_model": "esm2_t12_35M_UR50D",
    "multimodal_strategy": "cross-attention",
    "protein_layer_to_use": -1,
    "perceiver_latent_size": 100,
    "num_perceiver_layers": 1,
    "multimodal_layers": "all",
    "enable_gradient_checkpointing": false,
    "lr": 1e-4,
    "weight_decay": 1e-4
  },
  "wandb": {
    "project": "Cprt-Paper"
  },
  "trainer": {
    "precision": "16-mixed",
    "n_vals_per_epoch": 5,
    "max_epochs": 5,
    "devices": 1
  }
}
