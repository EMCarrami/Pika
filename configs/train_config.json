{
  "seed": 7,
  "datamodule": {
    "data_dict_path": "uniref50_gptv5_data.pkl",
    "split_ratios": [0.88, 0.02, 0.1],
    "max_protein_length": 750,
    "max_text_length": 250,
    "data_field_names": "qa",
    "use_unreal_proteins": true,
    "sequence_placeholder": "<protein sequence placeholder> ",
    "subsample_data": 25000,
    "train_batch_size": 4,
    "eval_batch_size": 16,
    "num_workers": 4
  },
  "model": {
    "multimodal_strategy": "cross-attention",
    "language_model": "gpt2-medium",
    "protein_model": "esm2_t12_35M_UR50D",
    "protein_layer_to_use": -1,
    "perceiver_latent_size": 100,
    "num_perceiver_layers": 1,
    "enable_gradient_checkpointing": false
  },
  "wandb": {
    "project": "Cprt-Experiments"
  },
  "trainer": {
    "precision": "16-mixed",
    "n_vals_per_epoch": 5,
    "max_epochs": 5,
    "devices": 1
  }
}
