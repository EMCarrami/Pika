{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from analysis_utils import get_run_data, process_run_data, aggregate_metrics, METRIC_NAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear-yogurt-10 crisp-resonance-64 devoted-wildflower-61 summer-leaf-52 rural-glade-24 scarlet-totem-23 wise-bush-22 misunderstood-waterfall-21 fanciful-snowflake-36 vague-silence-25 iconic-sea-22 elated-frog-8 pretty-butterfly-6 efficient-frost-5 volcanic-lion-4 chocolate-pyramid-3 young-salad-2 autumn-wildflower-1 "
     ]
    }
   ],
   "source": [
    "data, config = get_run_data(\"eli-carrami/Cprt-Paper-Exp-1\")\n",
    "out = []\n",
    "best_basis = \"biochem/val_localization_f1\"\n",
    "use_last = False\n",
    "for d, c in zip(data, config):\n",
    "    llm = c['model']['value']['language_model']\n",
    "    if 'gpt' in llm:\n",
    "        h = d.iloc[-1].copy()\n",
    "    elif use_last:\n",
    "        d = d[d.epoch == 0]\n",
    "        h = d.iloc[-1].copy()\n",
    "    else:\n",
    "        h = d.iloc[d[best_basis].idxmax()].copy()\n",
    "    h['protein_layer_to_use'] = c['model']['value']['protein_layer_to_use']\n",
    "    h['protein_layer_to_use'] = -1 if h['protein_layer_to_use'] == 12 else h['protein_layer_to_use']\n",
    "    h['esm'] = c['model']['value']['protein_model']\n",
    "    h['llm'] = llm\n",
    "    h['strategy'] = c['model']['value']['multimodal_strategy']\n",
    "    h['seed'] = c['seed']['value']\n",
    "    out.append(h)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "model_order = [\"esm2_t36_3B_UR50D\", \"esm2_t33_650M_UR50D\", \"esm2_t12_35M_UR50D\", \"esm2_t6_8M_UR50D\"]\n",
    "var = 'esm'\n",
    "fltr = [('strategy', \"soft-prompt\"), ('llm', \"gpt2-medium\")]\n",
    "ordering = (var, model_order)\n",
    "df = process_run_data(out, fltr, ordering)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "    biochem/val_is_real_f1  biochem/val_is_enzyme_hard_f1  \\\n13                0.990010                       0.868263   \n14                0.984027                       0.840242   \n4                 0.988138                       0.863928   \n5                 0.990029                       0.878154   \n12                0.960076                       0.836139   \n7                 0.978254                       0.839557   \n6                 0.973996                       0.832070   \n\n    biochem/val_kingdom_f1  biochem/val_localization_f1  biochem/val_cofactor  \\\n13                0.838981                     0.769025              0.222222   \n14                0.870506                     0.709540              0.305556   \n4                 0.896312                     0.722203              0.394231   \n5                 0.922889                     0.654014              0.260274   \n12                0.668738                     0.680844              0.222222   \n7                 0.674763                     0.586473              0.211538   \n6                 0.769413                     0.674791              0.232877   \n\n    biochem/val_is_fake_f1  biochem/val_mw_error  metrics/val_perplexity  \\\n13                0.178689              0.216861                3.185420   \n14                0.009976              0.055413                3.080299   \n4                 0.132075              0.040675                3.016529   \n5                 0.169657              0.103959                3.068007   \n12                0.118233              0.224499                3.288699   \n7                 0.223926              0.143106                3.197092   \n6                 0.034633              0.066999                3.279284   \n\n    metrics/val_rouge1_fmeasure  metrics/val_rouge1_precision  ...  \\\n13                     0.598898                      0.604275  ...   \n14                     0.582835                      0.573277  ...   \n4                      0.595260                      0.593815  ...   \n5                      0.617433                      0.643394  ...   \n12                     0.597508                      0.609539  ...   \n7                      0.599283                      0.606511  ...   \n6                      0.611650                      0.639912  ...   \n\n    biochem/val_in_membrane_f1  biochem/val_in_nucleus_f1  \\\n13                    0.205802                   0.183664   \n14                    0.396047                   0.341236   \n4                     0.197922                   0.132412   \n5                     0.225380                   0.123733   \n12                    0.189411                   0.170015   \n7                     0.374451                   0.372283   \n6                     0.326909                   0.213632   \n\n    biochem/val_in_mitochondria_f1  epoch  protein_layer_to_use  \\\n13                        0.147578    4.0                  -1.0   \n14                        0.388061    4.0                  -1.0   \n4                         0.069166    4.0                  -1.0   \n5                         0.161129    4.0                  -1.0   \n12                        0.077547    4.0                  -1.0   \n7                         0.379022    4.0                  -1.0   \n6                         0.228344    4.0                  -1.0   \n\n                    esm          llm     strategy  seed  avg_binary_loc_f1  \n13    esm2_t36_3B_UR50D  gpt2-medium  soft-prompt     0           0.179015  \n14  esm2_t33_650M_UR50D  gpt2-medium  soft-prompt     0           0.375115  \n4   esm2_t33_650M_UR50D  gpt2-medium  soft-prompt     7           0.133167  \n5   esm2_t33_650M_UR50D  gpt2-medium  soft-prompt    42           0.170081  \n12     esm2_t6_8M_UR50D  gpt2-medium  soft-prompt     0           0.145657  \n7      esm2_t6_8M_UR50D  gpt2-medium  soft-prompt     7           0.375252  \n6      esm2_t6_8M_UR50D  gpt2-medium  soft-prompt    42           0.256295  \n\n[7 rows x 27 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>biochem/val_is_real_f1</th>\n      <th>biochem/val_is_enzyme_hard_f1</th>\n      <th>biochem/val_kingdom_f1</th>\n      <th>biochem/val_localization_f1</th>\n      <th>biochem/val_cofactor</th>\n      <th>biochem/val_is_fake_f1</th>\n      <th>biochem/val_mw_error</th>\n      <th>metrics/val_perplexity</th>\n      <th>metrics/val_rouge1_fmeasure</th>\n      <th>metrics/val_rouge1_precision</th>\n      <th>...</th>\n      <th>biochem/val_in_membrane_f1</th>\n      <th>biochem/val_in_nucleus_f1</th>\n      <th>biochem/val_in_mitochondria_f1</th>\n      <th>epoch</th>\n      <th>protein_layer_to_use</th>\n      <th>esm</th>\n      <th>llm</th>\n      <th>strategy</th>\n      <th>seed</th>\n      <th>avg_binary_loc_f1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>13</th>\n      <td>0.990010</td>\n      <td>0.868263</td>\n      <td>0.838981</td>\n      <td>0.769025</td>\n      <td>0.222222</td>\n      <td>0.178689</td>\n      <td>0.216861</td>\n      <td>3.185420</td>\n      <td>0.598898</td>\n      <td>0.604275</td>\n      <td>...</td>\n      <td>0.205802</td>\n      <td>0.183664</td>\n      <td>0.147578</td>\n      <td>4.0</td>\n      <td>-1.0</td>\n      <td>esm2_t36_3B_UR50D</td>\n      <td>gpt2-medium</td>\n      <td>soft-prompt</td>\n      <td>0</td>\n      <td>0.179015</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>0.984027</td>\n      <td>0.840242</td>\n      <td>0.870506</td>\n      <td>0.709540</td>\n      <td>0.305556</td>\n      <td>0.009976</td>\n      <td>0.055413</td>\n      <td>3.080299</td>\n      <td>0.582835</td>\n      <td>0.573277</td>\n      <td>...</td>\n      <td>0.396047</td>\n      <td>0.341236</td>\n      <td>0.388061</td>\n      <td>4.0</td>\n      <td>-1.0</td>\n      <td>esm2_t33_650M_UR50D</td>\n      <td>gpt2-medium</td>\n      <td>soft-prompt</td>\n      <td>0</td>\n      <td>0.375115</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.988138</td>\n      <td>0.863928</td>\n      <td>0.896312</td>\n      <td>0.722203</td>\n      <td>0.394231</td>\n      <td>0.132075</td>\n      <td>0.040675</td>\n      <td>3.016529</td>\n      <td>0.595260</td>\n      <td>0.593815</td>\n      <td>...</td>\n      <td>0.197922</td>\n      <td>0.132412</td>\n      <td>0.069166</td>\n      <td>4.0</td>\n      <td>-1.0</td>\n      <td>esm2_t33_650M_UR50D</td>\n      <td>gpt2-medium</td>\n      <td>soft-prompt</td>\n      <td>7</td>\n      <td>0.133167</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.990029</td>\n      <td>0.878154</td>\n      <td>0.922889</td>\n      <td>0.654014</td>\n      <td>0.260274</td>\n      <td>0.169657</td>\n      <td>0.103959</td>\n      <td>3.068007</td>\n      <td>0.617433</td>\n      <td>0.643394</td>\n      <td>...</td>\n      <td>0.225380</td>\n      <td>0.123733</td>\n      <td>0.161129</td>\n      <td>4.0</td>\n      <td>-1.0</td>\n      <td>esm2_t33_650M_UR50D</td>\n      <td>gpt2-medium</td>\n      <td>soft-prompt</td>\n      <td>42</td>\n      <td>0.170081</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>0.960076</td>\n      <td>0.836139</td>\n      <td>0.668738</td>\n      <td>0.680844</td>\n      <td>0.222222</td>\n      <td>0.118233</td>\n      <td>0.224499</td>\n      <td>3.288699</td>\n      <td>0.597508</td>\n      <td>0.609539</td>\n      <td>...</td>\n      <td>0.189411</td>\n      <td>0.170015</td>\n      <td>0.077547</td>\n      <td>4.0</td>\n      <td>-1.0</td>\n      <td>esm2_t6_8M_UR50D</td>\n      <td>gpt2-medium</td>\n      <td>soft-prompt</td>\n      <td>0</td>\n      <td>0.145657</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.978254</td>\n      <td>0.839557</td>\n      <td>0.674763</td>\n      <td>0.586473</td>\n      <td>0.211538</td>\n      <td>0.223926</td>\n      <td>0.143106</td>\n      <td>3.197092</td>\n      <td>0.599283</td>\n      <td>0.606511</td>\n      <td>...</td>\n      <td>0.374451</td>\n      <td>0.372283</td>\n      <td>0.379022</td>\n      <td>4.0</td>\n      <td>-1.0</td>\n      <td>esm2_t6_8M_UR50D</td>\n      <td>gpt2-medium</td>\n      <td>soft-prompt</td>\n      <td>7</td>\n      <td>0.375252</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.973996</td>\n      <td>0.832070</td>\n      <td>0.769413</td>\n      <td>0.674791</td>\n      <td>0.232877</td>\n      <td>0.034633</td>\n      <td>0.066999</td>\n      <td>3.279284</td>\n      <td>0.611650</td>\n      <td>0.639912</td>\n      <td>...</td>\n      <td>0.326909</td>\n      <td>0.213632</td>\n      <td>0.228344</td>\n      <td>4.0</td>\n      <td>-1.0</td>\n      <td>esm2_t6_8M_UR50D</td>\n      <td>gpt2-medium</td>\n      <td>soft-prompt</td>\n      <td>42</td>\n      <td>0.256295</td>\n    </tr>\n  </tbody>\n</table>\n<p>7 rows Ã— 27 columns</p>\n</div>"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elicarrami/PycharmProjects/cprt/cprt/analysis/analysis_utils.py:107: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n",
      "  return df.groupby(group_by).agg(['mean', 'std'])\n"
     ]
    },
    {
     "data": {
      "text/plain": "                      is_real F1 is_enzyme F1  kingdom F1 localization F1  \\\n                                                                            \nesm                                                                         \nesm2_t36_3B_UR50D     0.99 (nan)   0.87 (nan)  0.84 (nan)      0.77 (nan)   \nesm2_t33_650M_UR50D   0.99 (0.0)  0.86 (0.02)  0.9 (0.03)      0.7 (0.04)   \nesm2_t12_35M_UR50D     nan (nan)    nan (nan)   nan (nan)       nan (nan)   \nesm2_t6_8M_UR50D     0.97 (0.01)   0.84 (0.0)  0.7 (0.06)     0.65 (0.05)   \n\n                    cofactor Recall binary localization\\naverage F1  \\\n                                                                      \nesm                                                                   \nesm2_t36_3B_UR50D        0.22 (nan)                      0.18 (nan)   \nesm2_t33_650M_UR50D     0.32 (0.07)                     0.23 (0.13)   \nesm2_t12_35M_UR50D        nan (nan)                       nan (nan)   \nesm2_t6_8M_UR50D        0.22 (0.01)                     0.26 (0.11)   \n\n                      is_fake F1      MW MALE   perplexity in_membrane F1  \\\n                                                                            \nesm                                                                         \nesm2_t36_3B_UR50D     0.18 (nan)   0.22 (nan)   3.19 (nan)     0.21 (nan)   \nesm2_t33_650M_UR50D   0.1 (0.08)  0.07 (0.03)  3.05 (0.03)    0.27 (0.11)   \nesm2_t12_35M_UR50D     nan (nan)    nan (nan)    nan (nan)      nan (nan)   \nesm2_t6_8M_UR50D     0.13 (0.09)  0.14 (0.08)  3.26 (0.05)      0.3 (0.1)   \n\n                    in_nucleus F1 in_mitochondria F1  \n                                                      \nesm                                                   \nesm2_t36_3B_UR50D      0.18 (nan)         0.15 (nan)  \nesm2_t33_650M_UR50D    0.2 (0.12)        0.21 (0.16)  \nesm2_t12_35M_UR50D      nan (nan)          nan (nan)  \nesm2_t6_8M_UR50D      0.25 (0.11)        0.23 (0.15)  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead tr th {\n        text-align: left;\n    }\n\n    .dataframe thead tr:last-of-type th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr>\n      <th></th>\n      <th>is_real F1</th>\n      <th>is_enzyme F1</th>\n      <th>kingdom F1</th>\n      <th>localization F1</th>\n      <th>cofactor Recall</th>\n      <th>binary localization\\naverage F1</th>\n      <th>is_fake F1</th>\n      <th>MW MALE</th>\n      <th>perplexity</th>\n      <th>in_membrane F1</th>\n      <th>in_nucleus F1</th>\n      <th>in_mitochondria F1</th>\n    </tr>\n    <tr>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n    <tr>\n      <th>esm</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>esm2_t36_3B_UR50D</th>\n      <td>0.99 (nan)</td>\n      <td>0.87 (nan)</td>\n      <td>0.84 (nan)</td>\n      <td>0.77 (nan)</td>\n      <td>0.22 (nan)</td>\n      <td>0.18 (nan)</td>\n      <td>0.18 (nan)</td>\n      <td>0.22 (nan)</td>\n      <td>3.19 (nan)</td>\n      <td>0.21 (nan)</td>\n      <td>0.18 (nan)</td>\n      <td>0.15 (nan)</td>\n    </tr>\n    <tr>\n      <th>esm2_t33_650M_UR50D</th>\n      <td>0.99 (0.0)</td>\n      <td>0.86 (0.02)</td>\n      <td>0.9 (0.03)</td>\n      <td>0.7 (0.04)</td>\n      <td>0.32 (0.07)</td>\n      <td>0.23 (0.13)</td>\n      <td>0.1 (0.08)</td>\n      <td>0.07 (0.03)</td>\n      <td>3.05 (0.03)</td>\n      <td>0.27 (0.11)</td>\n      <td>0.2 (0.12)</td>\n      <td>0.21 (0.16)</td>\n    </tr>\n    <tr>\n      <th>esm2_t12_35M_UR50D</th>\n      <td>nan (nan)</td>\n      <td>nan (nan)</td>\n      <td>nan (nan)</td>\n      <td>nan (nan)</td>\n      <td>nan (nan)</td>\n      <td>nan (nan)</td>\n      <td>nan (nan)</td>\n      <td>nan (nan)</td>\n      <td>nan (nan)</td>\n      <td>nan (nan)</td>\n      <td>nan (nan)</td>\n      <td>nan (nan)</td>\n    </tr>\n    <tr>\n      <th>esm2_t6_8M_UR50D</th>\n      <td>0.97 (0.01)</td>\n      <td>0.84 (0.0)</td>\n      <td>0.7 (0.06)</td>\n      <td>0.65 (0.05)</td>\n      <td>0.22 (0.01)</td>\n      <td>0.26 (0.11)</td>\n      <td>0.13 (0.09)</td>\n      <td>0.14 (0.08)</td>\n      <td>3.26 (0.05)</td>\n      <td>0.3 (0.1)</td>\n      <td>0.25 (0.11)</td>\n      <td>0.23 (0.15)</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_names = {k:v for k, v in METRIC_NAMES.items() if 'rouge' not in k}\n",
    "agg_df = aggregate_metrics(df, group_by=var)\n",
    "agg_df = agg_df[[col for col in metrics_names]]\n",
    "\n",
    "for col, name in metrics_names.items():\n",
    "    agg_df[name] = round(agg_df[(col, 'mean')], 2).astype(str) + \" (\" + round(agg_df[(col, 'std')], 2).astype(str) + \")\"\n",
    "    agg_df.drop([(col, 'mean'), (col, 'std')], axis=1, inplace=True)\n",
    "\n",
    "agg_df.to_clipboard()\n",
    "agg_df"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
